{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cfac255f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math as mt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "615e9f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"Creditcard_data.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3f1d47dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>767</th>\n",
       "      <td>575</td>\n",
       "      <td>-0.572263</td>\n",
       "      <td>0.731748</td>\n",
       "      <td>1.541254</td>\n",
       "      <td>0.150506</td>\n",
       "      <td>1.108974</td>\n",
       "      <td>0.372152</td>\n",
       "      <td>1.084879</td>\n",
       "      <td>-0.146329</td>\n",
       "      <td>-0.274447</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.143508</td>\n",
       "      <td>-0.107582</td>\n",
       "      <td>-0.418263</td>\n",
       "      <td>-0.731029</td>\n",
       "      <td>0.877525</td>\n",
       "      <td>-0.364150</td>\n",
       "      <td>-0.177509</td>\n",
       "      <td>-0.256545</td>\n",
       "      <td>26.72</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>768</th>\n",
       "      <td>579</td>\n",
       "      <td>-1.296845</td>\n",
       "      <td>-0.511605</td>\n",
       "      <td>2.404726</td>\n",
       "      <td>-0.310762</td>\n",
       "      <td>-0.319551</td>\n",
       "      <td>-0.542842</td>\n",
       "      <td>-0.173310</td>\n",
       "      <td>0.260423</td>\n",
       "      <td>-1.202688</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.071270</td>\n",
       "      <td>-0.161175</td>\n",
       "      <td>0.088496</td>\n",
       "      <td>0.285390</td>\n",
       "      <td>0.281069</td>\n",
       "      <td>-0.370130</td>\n",
       "      <td>0.043410</td>\n",
       "      <td>0.092318</td>\n",
       "      <td>80.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>769</th>\n",
       "      <td>579</td>\n",
       "      <td>1.214170</td>\n",
       "      <td>0.210481</td>\n",
       "      <td>0.484651</td>\n",
       "      <td>0.479768</td>\n",
       "      <td>-0.261955</td>\n",
       "      <td>-0.527039</td>\n",
       "      <td>0.021782</td>\n",
       "      <td>-0.106888</td>\n",
       "      <td>-0.037631</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.224292</td>\n",
       "      <td>-0.594609</td>\n",
       "      <td>0.159877</td>\n",
       "      <td>0.091873</td>\n",
       "      <td>0.140964</td>\n",
       "      <td>0.227406</td>\n",
       "      <td>-0.017389</td>\n",
       "      <td>0.016030</td>\n",
       "      <td>5.98</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>770</th>\n",
       "      <td>580</td>\n",
       "      <td>1.267030</td>\n",
       "      <td>-0.071114</td>\n",
       "      <td>0.037680</td>\n",
       "      <td>0.512683</td>\n",
       "      <td>0.242392</td>\n",
       "      <td>0.705212</td>\n",
       "      <td>-0.226582</td>\n",
       "      <td>0.109483</td>\n",
       "      <td>0.657565</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.164468</td>\n",
       "      <td>-0.177225</td>\n",
       "      <td>-0.222918</td>\n",
       "      <td>-1.245505</td>\n",
       "      <td>0.678360</td>\n",
       "      <td>0.525059</td>\n",
       "      <td>0.002920</td>\n",
       "      <td>-0.003333</td>\n",
       "      <td>12.36</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>771</th>\n",
       "      <td>581</td>\n",
       "      <td>1.153758</td>\n",
       "      <td>0.132273</td>\n",
       "      <td>0.382969</td>\n",
       "      <td>1.405063</td>\n",
       "      <td>-0.224287</td>\n",
       "      <td>-0.197295</td>\n",
       "      <td>0.020653</td>\n",
       "      <td>0.029260</td>\n",
       "      <td>0.412254</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.107809</td>\n",
       "      <td>-0.125231</td>\n",
       "      <td>-0.057041</td>\n",
       "      <td>0.073082</td>\n",
       "      <td>0.633977</td>\n",
       "      <td>-0.310685</td>\n",
       "      <td>0.033590</td>\n",
       "      <td>0.015250</td>\n",
       "      <td>13.79</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>772 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Time        V1        V2        V3        V4        V5        V6  \\\n",
       "0       0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388   \n",
       "1       0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361   \n",
       "2       1 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499   \n",
       "3       1 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203   \n",
       "4       2 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921   \n",
       "..    ...       ...       ...       ...       ...       ...       ...   \n",
       "767   575 -0.572263  0.731748  1.541254  0.150506  1.108974  0.372152   \n",
       "768   579 -1.296845 -0.511605  2.404726 -0.310762 -0.319551 -0.542842   \n",
       "769   579  1.214170  0.210481  0.484651  0.479768 -0.261955 -0.527039   \n",
       "770   580  1.267030 -0.071114  0.037680  0.512683  0.242392  0.705212   \n",
       "771   581  1.153758  0.132273  0.382969  1.405063 -0.224287 -0.197295   \n",
       "\n",
       "           V7        V8        V9  ...       V21       V22       V23  \\\n",
       "0    0.239599  0.098698  0.363787  ... -0.018307  0.277838 -0.110474   \n",
       "1   -0.078803  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288   \n",
       "2    0.791461  0.247676 -1.514654  ...  0.247998  0.771679  0.909412   \n",
       "3    0.237609  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321   \n",
       "4    0.592941 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458   \n",
       "..        ...       ...       ...  ...       ...       ...       ...   \n",
       "767  1.084879 -0.146329 -0.274447  ... -0.143508 -0.107582 -0.418263   \n",
       "768 -0.173310  0.260423 -1.202688  ... -0.071270 -0.161175  0.088496   \n",
       "769  0.021782 -0.106888 -0.037631  ... -0.224292 -0.594609  0.159877   \n",
       "770 -0.226582  0.109483  0.657565  ... -0.164468 -0.177225 -0.222918   \n",
       "771  0.020653  0.029260  0.412254  ... -0.107809 -0.125231 -0.057041   \n",
       "\n",
       "          V24       V25       V26       V27       V28  Amount  Class  \n",
       "0    0.066928  0.128539 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1   -0.339846  0.167170  0.125895 -0.008983  0.014724    2.69      1  \n",
       "2   -0.689281 -0.327642 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "3   -1.175575  0.647376 -0.221929  0.062723  0.061458  123.50      0  \n",
       "4    0.141267 -0.206010  0.502292  0.219422  0.215153   69.99      0  \n",
       "..        ...       ...       ...       ...       ...     ...    ...  \n",
       "767 -0.731029  0.877525 -0.364150 -0.177509 -0.256545   26.72      0  \n",
       "768  0.285390  0.281069 -0.370130  0.043410  0.092318   80.00      0  \n",
       "769  0.091873  0.140964  0.227406 -0.017389  0.016030    5.98      0  \n",
       "770 -1.245505  0.678360  0.525059  0.002920 -0.003333   12.36      0  \n",
       "771  0.073082  0.633977 -0.310685  0.033590  0.015250   13.79      0  \n",
       "\n",
       "[772 rows x 31 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3c4e59f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data[\"Class\"]\n",
    "X = data[data.columns.drop(\"Class\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "81bf2a44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving notices: ...working... done\n",
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /Users/sidharths/miniconda3/envs/tensorflow\n",
      "\n",
      "  added / updated specs:\n",
      "    - imbalanced-learn\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    imbalanced-learn-0.10.1    |     pyhd8ed1ab_0         131 KB  conda-forge\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:         131 KB\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "  imbalanced-learn   conda-forge/noarch::imbalanced-learn-0.10.1-pyhd8ed1ab_0 \n",
      "\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages\n",
      "                                                                                \n",
      "Preparing transaction: done\n",
      "Verifying transaction: done\n",
      "Executing transaction: done\n"
     ]
    }
   ],
   "source": [
    "#!conda install -y imbalanced-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bcd738e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import ADASYN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "78ecd8ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "adasyn = ADASYN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8e7009fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_ada, y_ada = adasyn.fit_resample(X, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4fb6557a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    765\n",
       "0    763\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_ada.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a88dac93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    763\n",
       "1      9\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "561904da",
   "metadata": {},
   "source": [
    "# Random Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9eff90ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_size = 100  \n",
    "x_s1 = x_ada.sample(n=sample_size, random_state=42)  \n",
    "y_s1 = y_ada.sample(n=sample_size, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ea9ce53f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Time        V1        V2        V3        V4        V5        V6  \\\n",
      "439    317  1.384146 -0.729477  0.562339 -0.901506 -0.831961  0.299020   \n",
      "76      49 -0.549626  0.418949  1.729833  0.203065 -0.187012  0.253878   \n",
      "1142   482 -2.856602 -3.038685  1.335573  2.082775  1.557360 -0.767455   \n",
      "661    499  1.355790 -1.122921  1.191187 -0.576548 -1.708750  0.274721   \n",
      "1036   565  1.068195  0.449004  0.205163  0.866217 -0.366519 -1.086544   \n",
      "...    ...       ...       ...       ...       ...       ...       ...   \n",
      "614    463  1.298898 -1.050674 -0.301587 -2.698140 -1.081625 -0.983307   \n",
      "788    466 -0.850430  0.393357  1.683449  0.192398  0.933185 -0.871015   \n",
      "1084   516  0.028694  0.911183 -0.352965  1.829231 -0.414388 -1.191096   \n",
      "1446   570  0.973541  0.115279  0.495331  0.729835 -0.111857 -0.922549   \n",
      "1053   449 -2.123279  1.326414 -0.688602  2.464781 -0.046953 -1.052777   \n",
      "\n",
      "            V7        V8        V9  ...       V20       V21       V22  \\\n",
      "439  -1.086901  0.111688 -0.391830  ...  0.129870  0.354589  1.020045   \n",
      "76    0.500894  0.251256 -0.227985  ...  0.016970  0.115062  0.418529   \n",
      "1142 -0.111001  0.085658 -0.050535  ...  1.836811  0.618815  0.571682   \n",
      "661  -1.640785  0.295838  0.618649  ...  0.020548  0.302035  0.920013   \n",
      "1036 -0.045440 -0.125254 -0.133373  ... -0.063125 -0.244168 -0.778951   \n",
      "...        ...       ...       ...  ...       ...       ...       ...   \n",
      "614  -0.365931 -0.099132  0.618335  ... -0.551491 -0.270855 -0.123874   \n",
      "788   0.843929 -0.147736 -0.146268  ... -0.116481  0.055652  0.247674   \n",
      "1084 -0.811729  0.341205 -0.944180  ... -0.004688 -0.010033 -0.550196   \n",
      "1446 -0.097994 -0.123201  0.096819  ... -0.013191 -0.224992 -0.644824   \n",
      "1053 -1.612988  0.979593 -1.849945  ...  0.086088  0.287727 -0.086758   \n",
      "\n",
      "           V23       V24       V25       V26       V27       V28      Amount  \n",
      "439  -0.204474 -0.843692  0.492947  0.038608  0.053718  0.014774   19.990000  \n",
      "76   -0.065133  0.264981  0.003958  0.395969  0.027182  0.043506   59.990000  \n",
      "1142  1.182726 -0.394767  0.190338  0.035018 -0.229804 -0.001306  434.452936  \n",
      "661  -0.210219 -0.435499  0.450803  0.068454  0.062214  0.022191   22.830000  \n",
      "1036  0.096188  0.341910  0.211745  0.098821 -0.007147  0.021695    1.221515  \n",
      "...        ...       ...       ...       ...       ...       ...         ...  \n",
      "614  -0.113170  0.224146  0.729243 -0.658224  0.073130  0.006890   37.570000  \n",
      "788  -0.244806  0.358817  0.382914 -0.432616 -0.100951 -0.120619    1.061908  \n",
      "1084 -0.076446  0.335234  0.160322  0.123120  0.075354 -0.029035    0.845892  \n",
      "1446  0.142505  0.238447  0.182706  0.161254 -0.031123  0.013326    1.308316  \n",
      "1053 -0.398237  0.136511 -0.080501  0.198420  0.061450 -0.222422    0.329381  \n",
      "\n",
      "[100 rows x 30 columns] 439     0\n",
      "76      0\n",
      "1142    1\n",
      "661     0\n",
      "1036    1\n",
      "       ..\n",
      "614     0\n",
      "788     1\n",
      "1084    1\n",
      "1446    1\n",
      "1053    1\n",
      "Name: Class, Length: 100, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(x_s1,y_s1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "183643dc",
   "metadata": {},
   "source": [
    "# Sytematic Sampling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c2065069",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Time        V1        V2        V3        V4        V5        V6  \\\n",
      "5        2 -0.425966  0.960523  1.141109 -0.168252  0.420987 -0.029728   \n",
      "20      16  0.694885 -1.361819  1.029221  0.834159 -1.191209  1.309109   \n",
      "35      26 -0.535388  0.865268  1.351076  0.147575  0.433680  0.086983   \n",
      "50      35  1.199356  0.129953  0.863585  1.002635 -0.783761 -0.884679   \n",
      "65      44 -0.899992  0.136255  1.883665 -0.208996  1.051441  1.905241   \n",
      "...    ...       ...       ...       ...       ...       ...       ...   \n",
      "1460   562  0.968116  0.369172  0.496945  0.623337 -0.182348 -1.045424   \n",
      "1475   554 -0.129975 -0.853421  1.226956  0.882043  0.843153 -0.359750   \n",
      "1490   543 -0.933878 -1.559112  1.759940  0.992925  1.538871  0.050245   \n",
      "1505   557  0.846001  0.371041  0.577070  0.594958 -0.108370 -1.036124   \n",
      "1520   178  0.116221  0.544312  0.446660  0.135733  0.780348  0.203895   \n",
      "\n",
      "            V7        V8        V9  ...       V20       V21       V22  \\\n",
      "5     0.476201  0.260314 -0.568671  ...  0.084968 -0.208254 -0.559825   \n",
      "20   -0.878586  0.445290 -0.446196  ... -0.138334 -0.295583 -0.571955   \n",
      "35    0.693039  0.179742 -0.285642  ... -0.283264  0.049526  0.206537   \n",
      "50   -0.040743 -0.208069  0.392478  ... -0.072620 -0.042468  0.198474   \n",
      "65    0.241423  0.647631 -0.053466  ... -0.121726 -0.081500 -0.016926   \n",
      "...        ...       ...       ...  ...       ...       ...       ...   \n",
      "1460  0.198245 -0.203184 -0.006290  ... -0.079675 -0.240059 -0.674646   \n",
      "1475 -0.844598  0.215020  0.416652  ...  0.222082  0.015236  0.037972   \n",
      "1490 -1.388494  0.461412  0.649649  ...  0.393477  0.190241  0.535384   \n",
      "1505  0.242086 -0.200184 -0.015037  ... -0.082162 -0.220326 -0.613079   \n",
      "1520  0.289029  0.126877 -0.118089  ... -0.044997 -0.134462 -0.397761   \n",
      "\n",
      "           V23       V24       V25       V26       V27       V28      Amount  \n",
      "5    -0.026398 -0.371427 -0.232794  0.105915  0.253844  0.081080    3.670000  \n",
      "20   -0.050881 -0.304215  0.072001 -0.422234  0.086553  0.063499  231.710000  \n",
      "35   -0.187108  0.000753  0.098117 -0.553471 -0.078306  0.025427    1.770000  \n",
      "50   -0.033010  1.013290  0.559098  0.401818 -0.005865  0.017936    0.990000  \n",
      "65   -0.147706 -1.384620 -0.024352  0.412659 -0.106776 -0.190476   21.550000  \n",
      "...        ...       ...       ...       ...       ...       ...         ...  \n",
      "1460  0.076570  0.348726  0.243643  0.021753 -0.033088  0.010181    1.251577  \n",
      "1475  0.200139 -0.168047  0.033537  0.420895 -0.065815 -0.055089    1.379438  \n",
      "1490  0.242126 -0.464176 -0.075131  0.610042 -0.091088 -0.104929    1.431251  \n",
      "1505  0.055026  0.351087  0.253141 -0.008876 -0.037683  0.001426    1.235376  \n",
      "1520  0.150169 -1.302379 -1.330987  0.076097  0.222588  0.222983    1.000823  \n",
      "\n",
      "[102 rows x 30 columns] 5       0\n",
      "20      0\n",
      "35      0\n",
      "50      0\n",
      "65      0\n",
      "       ..\n",
      "1460    1\n",
      "1475    1\n",
      "1490    1\n",
      "1505    1\n",
      "1520    1\n",
      "Name: Class, Length: 102, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "interval = mt.floor(x_ada.shape[0]/100)\n",
    "start = 5\n",
    "x_s2 = x_ada.iloc[start::interval]\n",
    "y_s2 = y_ada.iloc[start::interval]\n",
    "print(x_s2,y_s2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8b7da9aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(102, 30)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_s2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a7c37d03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>772.000000</td>\n",
       "      <td>772.000000</td>\n",
       "      <td>772.000000</td>\n",
       "      <td>772.000000</td>\n",
       "      <td>772.000000</td>\n",
       "      <td>772.000000</td>\n",
       "      <td>772.000000</td>\n",
       "      <td>772.000000</td>\n",
       "      <td>772.000000</td>\n",
       "      <td>772.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>772.000000</td>\n",
       "      <td>772.000000</td>\n",
       "      <td>772.000000</td>\n",
       "      <td>772.000000</td>\n",
       "      <td>772.000000</td>\n",
       "      <td>772.000000</td>\n",
       "      <td>772.000000</td>\n",
       "      <td>772.000000</td>\n",
       "      <td>772.000000</td>\n",
       "      <td>772.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>283.005181</td>\n",
       "      <td>-0.176963</td>\n",
       "      <td>0.217169</td>\n",
       "      <td>0.875172</td>\n",
       "      <td>0.285628</td>\n",
       "      <td>-0.005029</td>\n",
       "      <td>0.159081</td>\n",
       "      <td>0.123329</td>\n",
       "      <td>-0.057547</td>\n",
       "      <td>-0.030384</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004888</td>\n",
       "      <td>-0.096995</td>\n",
       "      <td>-0.040344</td>\n",
       "      <td>-0.002501</td>\n",
       "      <td>0.114337</td>\n",
       "      <td>0.022782</td>\n",
       "      <td>0.023353</td>\n",
       "      <td>-0.017045</td>\n",
       "      <td>68.668290</td>\n",
       "      <td>0.011658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>171.834196</td>\n",
       "      <td>1.294724</td>\n",
       "      <td>1.173401</td>\n",
       "      <td>1.031878</td>\n",
       "      <td>1.258758</td>\n",
       "      <td>1.098143</td>\n",
       "      <td>1.225682</td>\n",
       "      <td>0.852075</td>\n",
       "      <td>0.830144</td>\n",
       "      <td>0.878183</td>\n",
       "      <td>...</td>\n",
       "      <td>0.609335</td>\n",
       "      <td>0.607228</td>\n",
       "      <td>0.358724</td>\n",
       "      <td>0.621507</td>\n",
       "      <td>0.429667</td>\n",
       "      <td>0.484227</td>\n",
       "      <td>0.300934</td>\n",
       "      <td>0.278332</td>\n",
       "      <td>197.838269</td>\n",
       "      <td>0.107411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-6.093248</td>\n",
       "      <td>-12.114213</td>\n",
       "      <td>-5.694973</td>\n",
       "      <td>-4.657545</td>\n",
       "      <td>-6.631951</td>\n",
       "      <td>-3.498447</td>\n",
       "      <td>-4.925568</td>\n",
       "      <td>-7.494658</td>\n",
       "      <td>-2.770089</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.134608</td>\n",
       "      <td>-2.776923</td>\n",
       "      <td>-3.553381</td>\n",
       "      <td>-1.867208</td>\n",
       "      <td>-1.389079</td>\n",
       "      <td>-1.243924</td>\n",
       "      <td>-2.377933</td>\n",
       "      <td>-2.735623</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>126.500000</td>\n",
       "      <td>-0.896416</td>\n",
       "      <td>-0.174684</td>\n",
       "      <td>0.308677</td>\n",
       "      <td>-0.460058</td>\n",
       "      <td>-0.534567</td>\n",
       "      <td>-0.630717</td>\n",
       "      <td>-0.296289</td>\n",
       "      <td>-0.167880</td>\n",
       "      <td>-0.517068</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.213746</td>\n",
       "      <td>-0.525289</td>\n",
       "      <td>-0.176915</td>\n",
       "      <td>-0.379766</td>\n",
       "      <td>-0.166227</td>\n",
       "      <td>-0.313631</td>\n",
       "      <td>-0.047868</td>\n",
       "      <td>-0.033083</td>\n",
       "      <td>5.987500</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>282.000000</td>\n",
       "      <td>-0.382618</td>\n",
       "      <td>0.285843</td>\n",
       "      <td>0.905435</td>\n",
       "      <td>0.395919</td>\n",
       "      <td>-0.116612</td>\n",
       "      <td>-0.109581</td>\n",
       "      <td>0.116329</td>\n",
       "      <td>0.034755</td>\n",
       "      <td>-0.082270</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.075802</td>\n",
       "      <td>-0.076551</td>\n",
       "      <td>-0.048353</td>\n",
       "      <td>0.091886</td>\n",
       "      <td>0.143723</td>\n",
       "      <td>-0.026414</td>\n",
       "      <td>0.023199</td>\n",
       "      <td>0.021034</td>\n",
       "      <td>16.665000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>432.000000</td>\n",
       "      <td>1.110739</td>\n",
       "      <td>0.885745</td>\n",
       "      <td>1.532969</td>\n",
       "      <td>1.117559</td>\n",
       "      <td>0.452818</td>\n",
       "      <td>0.482972</td>\n",
       "      <td>0.575390</td>\n",
       "      <td>0.252395</td>\n",
       "      <td>0.412261</td>\n",
       "      <td>...</td>\n",
       "      <td>0.095149</td>\n",
       "      <td>0.307438</td>\n",
       "      <td>0.070085</td>\n",
       "      <td>0.426339</td>\n",
       "      <td>0.425798</td>\n",
       "      <td>0.260408</td>\n",
       "      <td>0.112199</td>\n",
       "      <td>0.087023</td>\n",
       "      <td>55.527500</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>581.000000</td>\n",
       "      <td>1.586093</td>\n",
       "      <td>5.267376</td>\n",
       "      <td>3.772857</td>\n",
       "      <td>4.075817</td>\n",
       "      <td>7.672544</td>\n",
       "      <td>5.122103</td>\n",
       "      <td>4.808426</td>\n",
       "      <td>2.134599</td>\n",
       "      <td>5.459274</td>\n",
       "      <td>...</td>\n",
       "      <td>5.273420</td>\n",
       "      <td>1.574750</td>\n",
       "      <td>3.150413</td>\n",
       "      <td>1.215279</td>\n",
       "      <td>1.136720</td>\n",
       "      <td>3.087444</td>\n",
       "      <td>2.490503</td>\n",
       "      <td>1.575380</td>\n",
       "      <td>3828.040000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Time          V1          V2          V3          V4          V5  \\\n",
       "count  772.000000  772.000000  772.000000  772.000000  772.000000  772.000000   \n",
       "mean   283.005181   -0.176963    0.217169    0.875172    0.285628   -0.005029   \n",
       "std    171.834196    1.294724    1.173401    1.031878    1.258758    1.098143   \n",
       "min      0.000000   -6.093248  -12.114213   -5.694973   -4.657545   -6.631951   \n",
       "25%    126.500000   -0.896416   -0.174684    0.308677   -0.460058   -0.534567   \n",
       "50%    282.000000   -0.382618    0.285843    0.905435    0.395919   -0.116612   \n",
       "75%    432.000000    1.110739    0.885745    1.532969    1.117559    0.452818   \n",
       "max    581.000000    1.586093    5.267376    3.772857    4.075817    7.672544   \n",
       "\n",
       "               V6          V7          V8          V9  ...         V21  \\\n",
       "count  772.000000  772.000000  772.000000  772.000000  ...  772.000000   \n",
       "mean     0.159081    0.123329   -0.057547   -0.030384  ...    0.004888   \n",
       "std      1.225682    0.852075    0.830144    0.878183  ...    0.609335   \n",
       "min     -3.498447   -4.925568   -7.494658   -2.770089  ...   -4.134608   \n",
       "25%     -0.630717   -0.296289   -0.167880   -0.517068  ...   -0.213746   \n",
       "50%     -0.109581    0.116329    0.034755   -0.082270  ...   -0.075802   \n",
       "75%      0.482972    0.575390    0.252395    0.412261  ...    0.095149   \n",
       "max      5.122103    4.808426    2.134599    5.459274  ...    5.273420   \n",
       "\n",
       "              V22         V23         V24         V25         V26         V27  \\\n",
       "count  772.000000  772.000000  772.000000  772.000000  772.000000  772.000000   \n",
       "mean    -0.096995   -0.040344   -0.002501    0.114337    0.022782    0.023353   \n",
       "std      0.607228    0.358724    0.621507    0.429667    0.484227    0.300934   \n",
       "min     -2.776923   -3.553381   -1.867208   -1.389079   -1.243924   -2.377933   \n",
       "25%     -0.525289   -0.176915   -0.379766   -0.166227   -0.313631   -0.047868   \n",
       "50%     -0.076551   -0.048353    0.091886    0.143723   -0.026414    0.023199   \n",
       "75%      0.307438    0.070085    0.426339    0.425798    0.260408    0.112199   \n",
       "max      1.574750    3.150413    1.215279    1.136720    3.087444    2.490503   \n",
       "\n",
       "              V28       Amount       Class  \n",
       "count  772.000000   772.000000  772.000000  \n",
       "mean    -0.017045    68.668290    0.011658  \n",
       "std      0.278332   197.838269    0.107411  \n",
       "min     -2.735623     0.000000    0.000000  \n",
       "25%     -0.033083     5.987500    0.000000  \n",
       "50%      0.021034    16.665000    0.000000  \n",
       "75%      0.087023    55.527500    0.000000  \n",
       "max      1.575380  3828.040000    1.000000  \n",
       "\n",
       "[8 rows x 31 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a410b7e",
   "metadata": {},
   "source": [
    "# Stratifed Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7b3ae3b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_s3_0=x_ada[y_ada.iloc[:]==0]\n",
    "x_s3_1=x_ada[y_ada.iloc[:]==1]\n",
    "y_s3_0=y_ada[y_ada.iloc[:]==0]\n",
    "y_s3_1=y_ada[y_ada.iloc[:]==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "41a5dc51",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_2/qv5cmtpd21z_6tm828cntvlr0000gn/T/ipykernel_46635/3050891127.py:2: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  x_s3=x_s3.append(x_s3_1.sample(50,random_state=42))\n",
      "/var/folders/_2/qv5cmtpd21z_6tm828cntvlr0000gn/T/ipykernel_46635/3050891127.py:4: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  y_s3=y_s3.append(y_s3_1.sample(50,random_state=42))\n"
     ]
    }
   ],
   "source": [
    "x_s3=x_s3_0.sample(50,random_state=42)\n",
    "x_s3=x_s3.append(x_s3_1.sample(50,random_state=42))\n",
    "y_s3=y_s3_0.sample(50,random_state=42)\n",
    "y_s3=y_s3.append(y_s3_1.sample(50,random_state=42))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f39b95c0",
   "metadata": {},
   "source": [
    "# Clustering\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ad066891",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt\n",
    "cs = []\n",
    "for i in range(1, 21):\n",
    "    kmeans = KMeans(n_clusters = i, init = 'k-means++', max_iter = 300, n_init = 10, random_state = 0)\n",
    "    kmeans.fit(x_ada)\n",
    "    cs.append(kmeans.inertia_)\n",
    "plt.plot(range(1, 21), cs)\n",
    "plt.title('The Elbow Method')\n",
    "plt.xlabel('Number of clusters')\n",
    "plt.ylabel('CS')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b89b5332",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
      "0     0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
      "1     0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
      "2     1 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
      "3     1 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
      "4     2 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
      "\n",
      "         V8        V9  ...       V22       V23       V24       V25       V26  \\\n",
      "0  0.098698  0.363787  ...  0.277838 -0.110474  0.066928  0.128539 -0.189115   \n",
      "1  0.085102 -0.255425  ... -0.638672  0.101288 -0.339846  0.167170  0.125895   \n",
      "2  0.247676 -1.514654  ...  0.771679  0.909412 -0.689281 -0.327642 -0.139097   \n",
      "3  0.377436 -1.387024  ...  0.005274 -0.190321 -1.175575  0.647376 -0.221929   \n",
      "4 -0.270533  0.817739  ...  0.798278 -0.137458  0.141267 -0.206010  0.502292   \n",
      "\n",
      "        V27       V28  Amount  Class  Cluster  \n",
      "0  0.133558 -0.021053  149.62      0        8  \n",
      "1 -0.008983  0.014724    2.69      1       13  \n",
      "2 -0.055353 -0.059752  378.66      0        4  \n",
      "3  0.062723  0.061458  123.50      0       13  \n",
      "4  0.219422  0.215153   69.99      0       13  \n",
      "\n",
      "[5 rows x 32 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sidharths/miniconda3/envs/tensorflow/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "n_clusters = 14\n",
    "kmeans = KMeans(n_clusters=n_clusters,random_state=42)\n",
    "kmeans.fit(data)\n",
    "from sklearn.cluster import KMeans\n",
    "import numpy as np\n",
    "labels = kmeans.labels_\n",
    "cluster_data = pd.DataFrame({'Cluster': labels})\n",
    "\n",
    "data_with_clusters = pd.concat([data, cluster_data], axis=1)\n",
    "\n",
    "\n",
    "print(data_with_clusters.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "825ee29a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "      <th>Cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>767</th>\n",
       "      <td>575</td>\n",
       "      <td>-0.572263</td>\n",
       "      <td>0.731748</td>\n",
       "      <td>1.541254</td>\n",
       "      <td>0.150506</td>\n",
       "      <td>1.108974</td>\n",
       "      <td>0.372152</td>\n",
       "      <td>1.084879</td>\n",
       "      <td>-0.146329</td>\n",
       "      <td>-0.274447</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.107582</td>\n",
       "      <td>-0.418263</td>\n",
       "      <td>-0.731029</td>\n",
       "      <td>0.877525</td>\n",
       "      <td>-0.364150</td>\n",
       "      <td>-0.177509</td>\n",
       "      <td>-0.256545</td>\n",
       "      <td>26.72</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>768</th>\n",
       "      <td>579</td>\n",
       "      <td>-1.296845</td>\n",
       "      <td>-0.511605</td>\n",
       "      <td>2.404726</td>\n",
       "      <td>-0.310762</td>\n",
       "      <td>-0.319551</td>\n",
       "      <td>-0.542842</td>\n",
       "      <td>-0.173310</td>\n",
       "      <td>0.260423</td>\n",
       "      <td>-1.202688</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.161175</td>\n",
       "      <td>0.088496</td>\n",
       "      <td>0.285390</td>\n",
       "      <td>0.281069</td>\n",
       "      <td>-0.370130</td>\n",
       "      <td>0.043410</td>\n",
       "      <td>0.092318</td>\n",
       "      <td>80.00</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>769</th>\n",
       "      <td>579</td>\n",
       "      <td>1.214170</td>\n",
       "      <td>0.210481</td>\n",
       "      <td>0.484651</td>\n",
       "      <td>0.479768</td>\n",
       "      <td>-0.261955</td>\n",
       "      <td>-0.527039</td>\n",
       "      <td>0.021782</td>\n",
       "      <td>-0.106888</td>\n",
       "      <td>-0.037631</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.594609</td>\n",
       "      <td>0.159877</td>\n",
       "      <td>0.091873</td>\n",
       "      <td>0.140964</td>\n",
       "      <td>0.227406</td>\n",
       "      <td>-0.017389</td>\n",
       "      <td>0.016030</td>\n",
       "      <td>5.98</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>770</th>\n",
       "      <td>580</td>\n",
       "      <td>1.267030</td>\n",
       "      <td>-0.071114</td>\n",
       "      <td>0.037680</td>\n",
       "      <td>0.512683</td>\n",
       "      <td>0.242392</td>\n",
       "      <td>0.705212</td>\n",
       "      <td>-0.226582</td>\n",
       "      <td>0.109483</td>\n",
       "      <td>0.657565</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.177225</td>\n",
       "      <td>-0.222918</td>\n",
       "      <td>-1.245505</td>\n",
       "      <td>0.678360</td>\n",
       "      <td>0.525059</td>\n",
       "      <td>0.002920</td>\n",
       "      <td>-0.003333</td>\n",
       "      <td>12.36</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>771</th>\n",
       "      <td>581</td>\n",
       "      <td>1.153758</td>\n",
       "      <td>0.132273</td>\n",
       "      <td>0.382969</td>\n",
       "      <td>1.405063</td>\n",
       "      <td>-0.224287</td>\n",
       "      <td>-0.197295</td>\n",
       "      <td>0.020653</td>\n",
       "      <td>0.029260</td>\n",
       "      <td>0.412254</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.125231</td>\n",
       "      <td>-0.057041</td>\n",
       "      <td>0.073082</td>\n",
       "      <td>0.633977</td>\n",
       "      <td>-0.310685</td>\n",
       "      <td>0.033590</td>\n",
       "      <td>0.015250</td>\n",
       "      <td>13.79</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>772 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Time        V1        V2        V3        V4        V5        V6  \\\n",
       "0       0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388   \n",
       "1       0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361   \n",
       "2       1 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499   \n",
       "3       1 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203   \n",
       "4       2 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921   \n",
       "..    ...       ...       ...       ...       ...       ...       ...   \n",
       "767   575 -0.572263  0.731748  1.541254  0.150506  1.108974  0.372152   \n",
       "768   579 -1.296845 -0.511605  2.404726 -0.310762 -0.319551 -0.542842   \n",
       "769   579  1.214170  0.210481  0.484651  0.479768 -0.261955 -0.527039   \n",
       "770   580  1.267030 -0.071114  0.037680  0.512683  0.242392  0.705212   \n",
       "771   581  1.153758  0.132273  0.382969  1.405063 -0.224287 -0.197295   \n",
       "\n",
       "           V7        V8        V9  ...       V22       V23       V24  \\\n",
       "0    0.239599  0.098698  0.363787  ...  0.277838 -0.110474  0.066928   \n",
       "1   -0.078803  0.085102 -0.255425  ... -0.638672  0.101288 -0.339846   \n",
       "2    0.791461  0.247676 -1.514654  ...  0.771679  0.909412 -0.689281   \n",
       "3    0.237609  0.377436 -1.387024  ...  0.005274 -0.190321 -1.175575   \n",
       "4    0.592941 -0.270533  0.817739  ...  0.798278 -0.137458  0.141267   \n",
       "..        ...       ...       ...  ...       ...       ...       ...   \n",
       "767  1.084879 -0.146329 -0.274447  ... -0.107582 -0.418263 -0.731029   \n",
       "768 -0.173310  0.260423 -1.202688  ... -0.161175  0.088496  0.285390   \n",
       "769  0.021782 -0.106888 -0.037631  ... -0.594609  0.159877  0.091873   \n",
       "770 -0.226582  0.109483  0.657565  ... -0.177225 -0.222918 -1.245505   \n",
       "771  0.020653  0.029260  0.412254  ... -0.125231 -0.057041  0.073082   \n",
       "\n",
       "          V25       V26       V27       V28  Amount  Class  Cluster  \n",
       "0    0.128539 -0.189115  0.133558 -0.021053  149.62      0        8  \n",
       "1    0.167170  0.125895 -0.008983  0.014724    2.69      1       13  \n",
       "2   -0.327642 -0.139097 -0.055353 -0.059752  378.66      0        4  \n",
       "3    0.647376 -0.221929  0.062723  0.061458  123.50      0       13  \n",
       "4   -0.206010  0.502292  0.219422  0.215153   69.99      0       13  \n",
       "..        ...       ...       ...       ...     ...    ...      ...  \n",
       "767  0.877525 -0.364150 -0.177509 -0.256545   26.72      0        1  \n",
       "768  0.281069 -0.370130  0.043410  0.092318   80.00      0        1  \n",
       "769  0.140964  0.227406 -0.017389  0.016030    5.98      0        1  \n",
       "770  0.678360  0.525059  0.002920 -0.003333   12.36      0        1  \n",
       "771  0.633977 -0.310685  0.033590  0.015250   13.79      0        1  \n",
       "\n",
       "[772 rows x 32 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_with_clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "befc2a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters = {}\n",
    "for i, label in enumerate(labels):\n",
    "    if label not in clusters:\n",
    "        clusters[label] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "aa088d91",
   "metadata": {},
   "outputs": [],
   "source": [
    "p=list(clusters.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6761b0e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "cluster_dfs = {}\n",
    "for i, data_with_clusters in data_with_clusters.groupby('Cluster'):\n",
    "    cluster_dfs[i] = pd.DataFrame(data_with_clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b3171e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_rows = []\n",
    "\n",
    "for key in cluster_dfs.keys():\n",
    "    rows = cluster_dfs[key].sample(n=10, random_state=42,replace=True)\n",
    "    selected_rows.append(rows)\n",
    "\n",
    "selected_df = pd.concat(selected_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a16d1325",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_s4=selected_df['Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ba863a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_s4=selected_df[selected_df.columns.drop(\"Cluster\")]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "aefb5fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_s4=x_s4[x_s4.columns.drop(\"Class\")]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6244b656",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>215</th>\n",
       "      <td>142</td>\n",
       "      <td>1.211406</td>\n",
       "      <td>0.007850</td>\n",
       "      <td>0.950798</td>\n",
       "      <td>1.137646</td>\n",
       "      <td>-0.495189</td>\n",
       "      <td>0.301371</td>\n",
       "      <td>-0.518350</td>\n",
       "      <td>0.095426</td>\n",
       "      <td>0.817592</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.049912</td>\n",
       "      <td>-0.107248</td>\n",
       "      <td>-0.057153</td>\n",
       "      <td>-0.118933</td>\n",
       "      <td>-0.421241</td>\n",
       "      <td>0.556146</td>\n",
       "      <td>-0.360164</td>\n",
       "      <td>0.076930</td>\n",
       "      <td>0.031800</td>\n",
       "      <td>9.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>105</td>\n",
       "      <td>1.175094</td>\n",
       "      <td>0.408263</td>\n",
       "      <td>0.552145</td>\n",
       "      <td>1.255068</td>\n",
       "      <td>-0.196662</td>\n",
       "      <td>-0.565605</td>\n",
       "      <td>0.133973</td>\n",
       "      <td>-0.146202</td>\n",
       "      <td>-0.214155</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.116439</td>\n",
       "      <td>0.130585</td>\n",
       "      <td>0.523640</td>\n",
       "      <td>-0.050125</td>\n",
       "      <td>0.448133</td>\n",
       "      <td>0.597867</td>\n",
       "      <td>-0.275067</td>\n",
       "      <td>0.043308</td>\n",
       "      <td>0.023924</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241</th>\n",
       "      <td>162</td>\n",
       "      <td>1.039964</td>\n",
       "      <td>-0.534355</td>\n",
       "      <td>1.865190</td>\n",
       "      <td>1.145122</td>\n",
       "      <td>-1.488133</td>\n",
       "      <td>0.589641</td>\n",
       "      <td>-1.119900</td>\n",
       "      <td>0.382781</td>\n",
       "      <td>1.419160</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.053880</td>\n",
       "      <td>-0.014701</td>\n",
       "      <td>0.430843</td>\n",
       "      <td>-0.071344</td>\n",
       "      <td>0.638434</td>\n",
       "      <td>0.366778</td>\n",
       "      <td>0.451211</td>\n",
       "      <td>0.053840</td>\n",
       "      <td>0.023451</td>\n",
       "      <td>22.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225</th>\n",
       "      <td>147</td>\n",
       "      <td>-2.687978</td>\n",
       "      <td>4.390230</td>\n",
       "      <td>-2.360483</td>\n",
       "      <td>0.360829</td>\n",
       "      <td>1.310192</td>\n",
       "      <td>-1.645253</td>\n",
       "      <td>2.327776</td>\n",
       "      <td>-1.727825</td>\n",
       "      <td>4.324752</td>\n",
       "      <td>...</td>\n",
       "      <td>3.169344</td>\n",
       "      <td>-1.045961</td>\n",
       "      <td>-0.156951</td>\n",
       "      <td>0.079854</td>\n",
       "      <td>-0.012598</td>\n",
       "      <td>0.207194</td>\n",
       "      <td>-0.536578</td>\n",
       "      <td>0.950393</td>\n",
       "      <td>-0.624431</td>\n",
       "      <td>0.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>112</td>\n",
       "      <td>1.102698</td>\n",
       "      <td>0.103965</td>\n",
       "      <td>0.934479</td>\n",
       "      <td>1.152704</td>\n",
       "      <td>-0.693597</td>\n",
       "      <td>-0.584580</td>\n",
       "      <td>-0.148439</td>\n",
       "      <td>-0.112031</td>\n",
       "      <td>0.196750</td>\n",
       "      <td>...</td>\n",
       "      <td>0.037095</td>\n",
       "      <td>-0.017211</td>\n",
       "      <td>-0.098781</td>\n",
       "      <td>0.003331</td>\n",
       "      <td>0.394412</td>\n",
       "      <td>0.334208</td>\n",
       "      <td>-0.520700</td>\n",
       "      <td>0.045952</td>\n",
       "      <td>0.048005</td>\n",
       "      <td>54.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>18</td>\n",
       "      <td>0.247491</td>\n",
       "      <td>0.277666</td>\n",
       "      <td>1.185471</td>\n",
       "      <td>-0.092603</td>\n",
       "      <td>-1.314394</td>\n",
       "      <td>-0.150116</td>\n",
       "      <td>-0.946365</td>\n",
       "      <td>-1.617935</td>\n",
       "      <td>1.544071</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.230983</td>\n",
       "      <td>1.650180</td>\n",
       "      <td>0.200454</td>\n",
       "      <td>-0.185353</td>\n",
       "      <td>0.423073</td>\n",
       "      <td>0.820591</td>\n",
       "      <td>-0.227632</td>\n",
       "      <td>0.336634</td>\n",
       "      <td>0.250475</td>\n",
       "      <td>22.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>74</td>\n",
       "      <td>1.038370</td>\n",
       "      <td>0.127486</td>\n",
       "      <td>0.184456</td>\n",
       "      <td>1.109950</td>\n",
       "      <td>0.441699</td>\n",
       "      <td>0.945283</td>\n",
       "      <td>-0.036715</td>\n",
       "      <td>0.350995</td>\n",
       "      <td>0.118950</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.335520</td>\n",
       "      <td>0.102520</td>\n",
       "      <td>0.605089</td>\n",
       "      <td>0.023092</td>\n",
       "      <td>-0.626463</td>\n",
       "      <td>0.479120</td>\n",
       "      <td>-0.166937</td>\n",
       "      <td>0.081247</td>\n",
       "      <td>0.001192</td>\n",
       "      <td>1.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>83</td>\n",
       "      <td>-1.864990</td>\n",
       "      <td>0.910874</td>\n",
       "      <td>1.724863</td>\n",
       "      <td>-1.748371</td>\n",
       "      <td>0.578943</td>\n",
       "      <td>-0.832531</td>\n",
       "      <td>1.901440</td>\n",
       "      <td>-1.913986</td>\n",
       "      <td>2.112375</td>\n",
       "      <td>...</td>\n",
       "      <td>0.274877</td>\n",
       "      <td>-0.318597</td>\n",
       "      <td>0.073323</td>\n",
       "      <td>-0.061693</td>\n",
       "      <td>0.547204</td>\n",
       "      <td>-0.466798</td>\n",
       "      <td>0.408030</td>\n",
       "      <td>-2.377933</td>\n",
       "      <td>-1.255549</td>\n",
       "      <td>7.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>52</td>\n",
       "      <td>1.147369</td>\n",
       "      <td>0.059035</td>\n",
       "      <td>0.263632</td>\n",
       "      <td>1.211023</td>\n",
       "      <td>-0.044096</td>\n",
       "      <td>0.301067</td>\n",
       "      <td>-0.132960</td>\n",
       "      <td>0.227885</td>\n",
       "      <td>0.252191</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.255924</td>\n",
       "      <td>-0.087813</td>\n",
       "      <td>-0.110756</td>\n",
       "      <td>-0.097771</td>\n",
       "      <td>-0.323374</td>\n",
       "      <td>0.633279</td>\n",
       "      <td>-0.305328</td>\n",
       "      <td>0.027394</td>\n",
       "      <td>-0.000580</td>\n",
       "      <td>6.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>67</td>\n",
       "      <td>-0.653445</td>\n",
       "      <td>0.160225</td>\n",
       "      <td>1.592256</td>\n",
       "      <td>1.296832</td>\n",
       "      <td>0.997175</td>\n",
       "      <td>-0.343000</td>\n",
       "      <td>0.469937</td>\n",
       "      <td>-0.132470</td>\n",
       "      <td>-0.197794</td>\n",
       "      <td>...</td>\n",
       "      <td>0.225920</td>\n",
       "      <td>0.038363</td>\n",
       "      <td>0.336449</td>\n",
       "      <td>-0.014883</td>\n",
       "      <td>0.102959</td>\n",
       "      <td>-0.265322</td>\n",
       "      <td>-0.348637</td>\n",
       "      <td>0.011238</td>\n",
       "      <td>-0.049478</td>\n",
       "      <td>19.85</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>140 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Time        V1        V2        V3        V4        V5        V6  \\\n",
       "215   142  1.211406  0.007850  0.950798  1.137646 -0.495189  0.301371   \n",
       "166   105  1.175094  0.408263  0.552145  1.255068 -0.196662 -0.565605   \n",
       "241   162  1.039964 -0.534355  1.865190  1.145122 -1.488133  0.589641   \n",
       "225   147 -2.687978  4.390230 -2.360483  0.360829  1.310192 -1.645253   \n",
       "175   112  1.102698  0.103965  0.934479  1.152704 -0.693597 -0.584580   \n",
       "..    ...       ...       ...       ...       ...       ...       ...   \n",
       "23     18  0.247491  0.277666  1.185471 -0.092603 -1.314394 -0.150116   \n",
       "113    74  1.038370  0.127486  0.184456  1.109950  0.441699  0.945283   \n",
       "132    83 -1.864990  0.910874  1.724863 -1.748371  0.578943 -0.832531   \n",
       "81     52  1.147369  0.059035  0.263632  1.211023 -0.044096  0.301067   \n",
       "97     67 -0.653445  0.160225  1.592256  1.296832  0.997175 -0.343000   \n",
       "\n",
       "           V7        V8        V9  ...       V20       V21       V22  \\\n",
       "215 -0.518350  0.095426  0.817592  ... -0.049912 -0.107248 -0.057153   \n",
       "166  0.133973 -0.146202 -0.214155  ... -0.116439  0.130585  0.523640   \n",
       "241 -1.119900  0.382781  1.419160  ... -0.053880 -0.014701  0.430843   \n",
       "225  2.327776 -1.727825  4.324752  ...  3.169344 -1.045961 -0.156951   \n",
       "175 -0.148439 -0.112031  0.196750  ...  0.037095 -0.017211 -0.098781   \n",
       "..        ...       ...       ...  ...       ...       ...       ...   \n",
       "23  -0.946365 -1.617935  1.544071  ... -0.230983  1.650180  0.200454   \n",
       "113 -0.036715  0.350995  0.118950  ... -0.335520  0.102520  0.605089   \n",
       "132  1.901440 -1.913986  2.112375  ...  0.274877 -0.318597  0.073323   \n",
       "81  -0.132960  0.227885  0.252191  ... -0.255924 -0.087813 -0.110756   \n",
       "97   0.469937 -0.132470 -0.197794  ...  0.225920  0.038363  0.336449   \n",
       "\n",
       "          V23       V24       V25       V26       V27       V28  Amount  \n",
       "215 -0.118933 -0.421241  0.556146 -0.360164  0.076930  0.031800    9.99  \n",
       "166 -0.050125  0.448133  0.597867 -0.275067  0.043308  0.023924    1.00  \n",
       "241 -0.071344  0.638434  0.366778  0.451211  0.053840  0.023451   22.00  \n",
       "225  0.079854 -0.012598  0.207194 -0.536578  0.950393 -0.624431    0.89  \n",
       "175  0.003331  0.394412  0.334208 -0.520700  0.045952  0.048005   54.99  \n",
       "..        ...       ...       ...       ...       ...       ...     ...  \n",
       "23  -0.185353  0.423073  0.820591 -0.227632  0.336634  0.250475   22.75  \n",
       "113  0.023092 -0.626463  0.479120 -0.166937  0.081247  0.001192    1.18  \n",
       "132 -0.061693  0.547204 -0.466798  0.408030 -2.377933 -1.255549    7.69  \n",
       "81  -0.097771 -0.323374  0.633279 -0.305328  0.027394 -0.000580    6.67  \n",
       "97  -0.014883  0.102959 -0.265322 -0.348637  0.011238 -0.049478   19.85  \n",
       "\n",
       "[140 rows x 30 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_s4\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3db4102",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad664178",
   "metadata": {},
   "source": [
    "## Model-1 Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4f5b0cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "m1_acc=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6bc131b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sidharths/miniconda3/envs/tensorflow/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.8959424083769634]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sample 1\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import datasets\n",
    "\n",
    "m1 = LogisticRegression()\n",
    "m1.fit(x_s1, y_s1)\n",
    "\n",
    "y_pred = m1.predict(x_ada)\n",
    "\n",
    "m1_acc.append(m1.score(x_ada, y_ada))\n",
    "m1_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d32cbe55",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sidharths/miniconda3/envs/tensorflow/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.8959424083769634, 0.8867801047120419]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sample 2\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import datasets\n",
    "\n",
    "\n",
    "m1 = LogisticRegression()\n",
    "m1.fit(x_s2, y_s2)\n",
    "\n",
    "y_pred = m1.predict(x_ada)\n",
    "\n",
    "m1_acc.append(m1.score(x_ada, y_ada))\n",
    "m1_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6f163004",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sidharths/miniconda3/envs/tensorflow/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.8959424083769634, 0.8867801047120419, 0.8913612565445026]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# smaple 3\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import datasets\n",
    "\n",
    "m1 = LogisticRegression()\n",
    "m1.fit(x_s3, y_s3)\n",
    "\n",
    "y_pred = m1.predict(x_ada)\n",
    "\n",
    "m1_acc.append(m1.score(x_ada, y_ada))\n",
    "m1_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1bfa1b5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sidharths/miniconda3/envs/tensorflow/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.8959424083769634,\n",
       " 0.8867801047120419,\n",
       " 0.8913612565445026,\n",
       " 0.5615183246073299]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sample 4\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import datasets\n",
    "\n",
    "m1 = LogisticRegression()\n",
    "m1.fit(x_s4, y_s4)\n",
    "\n",
    "y_pred = m1.predict(x_ada)\n",
    "\n",
    "m1_acc.append(m1.score(x_ada, y_ada))\n",
    "m1_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eacdc588",
   "metadata": {},
   "source": [
    "## Model-2 Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8bbbb107",
   "metadata": {},
   "outputs": [],
   "source": [
    "m2_acc=[]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b38aeb00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9770942408376964]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##sample 1\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "m2 = RandomForestClassifier()\n",
    "\n",
    "m2.fit(x_s1, y_s1)\n",
    "\n",
    "y_pred_m1_s1 = m2.predict(x_ada)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "m2_acc.append(accuracy_score(y_ada, y_pred_m1_s1))\n",
    "m2_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4aa1c306",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9770942408376964, 0.9770942408376964]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##sample 2\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "m2 = RandomForestClassifier()\n",
    "\n",
    "m2.fit(x_s2, y_s2)\n",
    "\n",
    "y_pred_m1_s2 = m2.predict(x_ada)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "m2_acc.append(accuracy_score(y_ada, y_pred_m1_s2))\n",
    "m2_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "71ca1fc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9770942408376964, 0.9770942408376964, 0.9646596858638743]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##sample 3\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "m2 = RandomForestClassifier()\n",
    "\n",
    "m2.fit(x_s3, y_s3)\n",
    "\n",
    "y_pred_m1_s3 = m2.predict(x_ada)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "m2_acc.append(accuracy_score(y_ada, y_pred_m1_s3))\n",
    "m2_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "077d2a3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9770942408376964,\n",
       " 0.9770942408376964,\n",
       " 0.9646596858638743,\n",
       " 0.5019633507853403]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##sample 4\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "m2 = RandomForestClassifier()\n",
    "\n",
    "m2.fit(x_s4, y_s4)\n",
    "\n",
    "y_pred_m1_s4 = m2.predict(x_ada)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "m2_acc.append(accuracy_score(y_ada, y_pred_m1_s4))\n",
    "m2_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff571aed",
   "metadata": {},
   "source": [
    "## Model-3 MLP Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "df410e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "m3_acc=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "9d1ecd7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sidharths/miniconda3/envs/tensorflow/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:684: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.9064136125654451]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import datasets\n",
    "\n",
    "m3 = MLPClassifier(random_state=1, max_iter=300).fit(x_s1, y_s1)\n",
    "\n",
    "\n",
    "y_pred = m3.predict(x_ada)\n",
    "\n",
    "m3_acc.append(m3.score(x_ada, y_ada))\n",
    "m3_acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "9bd8d17c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sidharths/miniconda3/envs/tensorflow/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:684: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.9064136125654451, 0.9155759162303665]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import datasets\n",
    "\n",
    "m3 = MLPClassifier(random_state=1, max_iter=300).fit(x_s2, y_s2)\n",
    "\n",
    "\n",
    "y_pred = m3.predict(x_ada)\n",
    "\n",
    "m3_acc.append(m3.score(x_ada, y_ada))\n",
    "m3_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "2fe5075e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sidharths/miniconda3/envs/tensorflow/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:684: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.9064136125654451, 0.9155759162303665, 0.9064136125654451]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import datasets\n",
    "\n",
    "m3 = MLPClassifier(random_state=1, max_iter=300).fit(x_s3, y_s3)\n",
    "\n",
    "\n",
    "y_pred = m3.predict(x_ada)\n",
    "\n",
    "m3_acc.append(m3.score(x_ada, y_ada))\n",
    "m3_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "a247a60a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9064136125654451,\n",
       " 0.9155759162303665,\n",
       " 0.9064136125654451,\n",
       " 0.4993455497382199]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import datasets\n",
    "\n",
    "m3 = MLPClassifier(random_state=1, max_iter=300).fit(x_s4, y_s4)\n",
    "\n",
    "\n",
    "y_pred = m3.predict(x_ada)\n",
    "\n",
    "m3_acc.append(m3.score(x_ada, y_ada))\n",
    "m3_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80610429",
   "metadata": {},
   "source": [
    "## Model-4 Passive Agressive Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "b0736f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "m4_acc = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "50efe4f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5019633507853403]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "from sklearn import datasets\n",
    "\n",
    "m4 = PassiveAggressiveClassifier(max_iter=1000, random_state=0, tol=1e-3)\n",
    "m4.fit(x_s1, y_s1)\n",
    "\n",
    "y_pred = m4.predict(x_ada)\n",
    "\n",
    "m4_acc.append(m4.score(x_ada, y_ada))\n",
    "m4_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "78e47cdb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5019633507853403, 0.5510471204188482]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "from sklearn import datasets\n",
    "\n",
    "m4 = PassiveAggressiveClassifier(max_iter=1000, random_state=0, tol=1e-3)\n",
    "m4.fit(x_s2, y_s2)\n",
    "\n",
    "y_pred = m4.predict(x_ada)\n",
    "\n",
    "m4_acc.append(m4.score(x_ada, y_ada))\n",
    "m4_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "f4628f97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5019633507853403, 0.5510471204188482, 0.5104712041884817]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "from sklearn import datasets\n",
    "\n",
    "m4 = PassiveAggressiveClassifier(max_iter=1000, random_state=0, tol=1e-3)\n",
    "m4.fit(x_s3, y_s3)\n",
    "\n",
    "y_pred = m4.predict(x_ada)\n",
    "\n",
    "m4_acc.append(m4.score(x_ada, y_ada))\n",
    "m4_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "fb4fc192",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5019633507853403,\n",
       " 0.5510471204188482,\n",
       " 0.5104712041884817,\n",
       " 0.4993455497382199]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "from sklearn import datasets\n",
    "\n",
    "m4 = PassiveAggressiveClassifier(max_iter=1000, random_state=0, tol=1e-3)\n",
    "m4.fit(x_s4, y_s4)\n",
    "\n",
    "y_pred = m4.predict(x_ada)\n",
    "\n",
    "m4_acc.append(m4.score(x_ada, y_ada))\n",
    "m4_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02fcca08",
   "metadata": {},
   "source": [
    "## Model-5 Ada Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "ecc8a2c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "m5_acc=[]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "d58184c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sidharths/miniconda3/envs/tensorflow/lib/python3.10/site-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.9718586387434555]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sample 1\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=15, max_depth=10)\n",
    "\n",
    "boost = AdaBoostClassifier(base_estimator=rf, n_estimators=30, learning_rate=0.1)\n",
    "\n",
    "boost.fit(x_s1, y_s1)\n",
    "\n",
    "y_pred = boost.predict(x_ada)\n",
    "m5_acc.append(accuracy_score(y_ada, y_pred))\n",
    "m5_acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "068fbc2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sidharths/miniconda3/envs/tensorflow/lib/python3.10/site-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.9718586387434555, 0.9705497382198953]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sample 2\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=15, max_depth=10)\n",
    "\n",
    "boost = AdaBoostClassifier(base_estimator=rf, n_estimators=30, learning_rate=0.1)\n",
    "\n",
    "boost.fit(x_s2, y_s2)\n",
    "\n",
    "y_pred = boost.predict(x_ada)\n",
    "m5_acc.append(accuracy_score(y_ada, y_pred))\n",
    "m5_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "64454c72",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sidharths/miniconda3/envs/tensorflow/lib/python3.10/site-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.9718586387434555, 0.9705497382198953, 0.9600785340314136]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sample 3\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=15, max_depth=10)\n",
    "\n",
    "boost = AdaBoostClassifier(base_estimator=rf, n_estimators=30, learning_rate=0.1)\n",
    "\n",
    "boost.fit(x_s3, y_s3)\n",
    "\n",
    "y_pred = boost.predict(x_ada)\n",
    "m5_acc.append(accuracy_score(y_ada, y_pred))\n",
    "m5_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "4f6763ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sidharths/miniconda3/envs/tensorflow/lib/python3.10/site-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.9718586387434555,\n",
       " 0.9705497382198953,\n",
       " 0.9600785340314136,\n",
       " 0.5045811518324608]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sample 2\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=15, max_depth=10)\n",
    "\n",
    "boost = AdaBoostClassifier(base_estimator=rf, n_estimators=30, learning_rate=0.1)\n",
    "\n",
    "boost.fit(x_s4, y_s4)\n",
    "\n",
    "y_pred = boost.predict(x_ada)\n",
    "m5_acc.append(accuracy_score(y_ada, y_pred))\n",
    "m5_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c70c7e4",
   "metadata": {},
   "source": [
    "## Model Comparision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "d30ec109",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_comparision = pd.DataFrame(data=[m1_acc,m2_acc,m3_acc,m4_acc,m5_acc])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "ac8332cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.895942</td>\n",
       "      <td>0.886780</td>\n",
       "      <td>0.891361</td>\n",
       "      <td>0.561518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.977094</td>\n",
       "      <td>0.977094</td>\n",
       "      <td>0.964660</td>\n",
       "      <td>0.501963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.906414</td>\n",
       "      <td>0.915576</td>\n",
       "      <td>0.906414</td>\n",
       "      <td>0.499346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.501963</td>\n",
       "      <td>0.551047</td>\n",
       "      <td>0.510471</td>\n",
       "      <td>0.499346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.971859</td>\n",
       "      <td>0.970550</td>\n",
       "      <td>0.960079</td>\n",
       "      <td>0.504581</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3\n",
       "0  0.895942  0.886780  0.891361  0.561518\n",
       "1  0.977094  0.977094  0.964660  0.501963\n",
       "2  0.906414  0.915576  0.906414  0.499346\n",
       "3  0.501963  0.551047  0.510471  0.499346\n",
       "4  0.971859  0.970550  0.960079  0.504581"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_comparision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "4ab1cd30",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_comparision.index=[\"Logistic Regression\",\"Random Forest\",\"MLP Claasifier\",\"PAC\",\"Ada Boost\"]\n",
    "model_comparision.columns=[\"Random\",\"Systematic\",\"Stratified\",\"Clustering\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "dc2cff3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Random</th>\n",
       "      <th>Systematic</th>\n",
       "      <th>Stratified</th>\n",
       "      <th>Clustering</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Logistic Regression</th>\n",
       "      <td>0.895942</td>\n",
       "      <td>0.886780</td>\n",
       "      <td>0.891361</td>\n",
       "      <td>0.561518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <td>0.977094</td>\n",
       "      <td>0.977094</td>\n",
       "      <td>0.964660</td>\n",
       "      <td>0.501963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP Claasifier</th>\n",
       "      <td>0.906414</td>\n",
       "      <td>0.915576</td>\n",
       "      <td>0.906414</td>\n",
       "      <td>0.499346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PAC</th>\n",
       "      <td>0.501963</td>\n",
       "      <td>0.551047</td>\n",
       "      <td>0.510471</td>\n",
       "      <td>0.499346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ada Boost</th>\n",
       "      <td>0.971859</td>\n",
       "      <td>0.970550</td>\n",
       "      <td>0.960079</td>\n",
       "      <td>0.504581</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Random  Systematic  Stratified  Clustering\n",
       "Logistic Regression  0.895942    0.886780    0.891361    0.561518\n",
       "Random Forest        0.977094    0.977094    0.964660    0.501963\n",
       "MLP Claasifier       0.906414    0.915576    0.906414    0.499346\n",
       "PAC                  0.501963    0.551047    0.510471    0.499346\n",
       "Ada Boost            0.971859    0.970550    0.960079    0.504581"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_comparision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "033f4969",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
